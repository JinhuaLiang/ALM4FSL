#!/bin/bash
#$ -l gpu=2
#$ -pe smp 16
#$ -l h_vmem=11G
#$ -l h_rt=10:0:0
#$ -wd /data/home/eey340/WORKPLACE/ALM4FSL/experiments/python
#$ -j y
#$ -N command
#$ -o /data/home/eey340/WORKPLACE/ALM4FSL/experiments/LOGS/F1shot_a1_sweep.log
#$ -m beas
#$ -l cluster=andrena

module load cudnn/8.1.1-cuda11
source ../../alm/bin/activate

gpu-usage
for EPOCH in 10 15 25 30
do
    python3 fewshot.py --n_supports 1 --fine_tune --train_epochs ${EPOCH} --train_lr 0.001
done


# Generated by Job Script Builder on 2022-01-20
# For assistance, please email its-research-support@qmul.ac.uk
#=================================COMMON CMD===================================#
## testify the code by using a short queue (shorter than 1 hour) on dn150
# -l h_rt=1:0:0    # 1 hour runtime
# -l gpu_type=kepler # it should work, but not get verified yet 

## select 8 cores per GPU, and 7.5GB per core, e.g.:
# -pe smp 8        # 8 cores
# -l h_vmem=7.5G   # 7.5 * 8 = 60G total RAM
# -l gpu=1         # request 1 GPU

# -l exclusive     # request exclusive access
